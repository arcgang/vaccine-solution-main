{"version":3,"sources":["webpack:///./src/pages/devops/build-run.mdx"],"names":["_frontmatter","layoutProps","MDXLayout","DefaultLayout","MDXContent","components","props","mdxType","parentName","isMDXComponent"],"mappings":"wPAQaA,G,UAAe,IACtBC,EAAc,CAClBD,gBAEIE,EAAYC,IACH,SAASC,EAAT,GAGZ,IAFDC,EAEC,EAFDA,WACGC,EACF,8BACD,OAAO,YAACJ,EAAD,eAAeD,EAAiBK,EAAhC,CAAuCD,WAAYA,EAAYE,QAAQ,cAG5E,4EACA,qEAAoD,iBAAGC,WAAW,IAC9D,KAAQ,qGADwC,0BAApD,kGAGA,sBACE,kBAAIA,WAAW,MAAf,mFAEF,6FAA4E,0BAAYA,WAAW,KAAvB,eAA5E,gIACA,2EACA,mCAAkB,0BAAYA,WAAW,KAAvB,uBAAlB,6CAA+H,0BAAYA,WAAW,KAAvB,uGAC/H,uBAAK,oBAAMA,WAAW,OAAjB,iKAIL,6JACA,+DAA8C,0BAAYA,WAAW,KAAvB,mCAA9C,gCACA,uBAAK,oBAAMA,WAAW,OAAjB,yMAIL,wFACA,sDACA,6LAA4K,0BAAYA,WAAW,KAAvB,0BAA5K,YACA,oFACA,uBAAK,oBAAMA,WAAW,MAClB,UAAa,mBADZ,4OAYL,qEACA,uBAAK,oBAAMA,WAAW,OAAjB,6NAKL,mKACA,uBAAK,oBAAMA,WAAW,MAClB,UAAa,mBADZ,ifAiBL,kHACA,uBAAK,oBAAMA,WAAW,OAAjB,+ZAML,iOACA,8DAA6C,iBAAGA,WAAW,IACvD,KAAQ,mGADiC,mBAA7C,yLAGA,uQACA,qCACA,8BAAa,0BAAYA,WAAW,KAAvB,0BAAb,mHACA,uBAAK,oBAAMA,WAAW,OAAjB,ihBAKL,6DACA,0HACA,uBAAK,oBAAMA,WAAW,OAAjB,kKAEL,8KAA6J,0BAAYA,WAAW,KAAvB,aAA7J,kIACA,mIACA,uBAAK,oBAAMA,WAAW,OAAjB,2NAIL,sKACA,uBAAK,oBAAMA,WAAW,OAAjB,0CAEL,kGACA,uBAAK,oBAAMA,WAAW,OAAjB,6FAGL,4EACA,uBAAK,oBAAMA,WAAW,OAAjB,mIAKL,wCACA,uBAAK,oBAAMA,WAAW,OAAjB,+CAEL,kJAAiI,0BAAYA,WAAW,KAAvB,eAAjI,mBAA4M,0BAAYA,WAAW,KAAvB,SAA5M,YACA,oHAAmG,0BAAYA,WAAW,KAAvB,SAAnG,gBACA,gCAAe,iBAAGA,WAAW,IACzB,KAAQ,sBADG,oBAAf,+DAGA,6CACA,+CACA,uBAAK,oBAAMA,WAAW,OAAjB,yBAGL,kDACA,iJAAgI,iBAAGA,WAAW,IAC1I,KAAQ,4FADoH,eAAhI,kBAOJJ,EAAWK,gBAAiB","file":"component---src-pages-devops-build-run-mdx-c78a842b0e4fc7f003e6.js","sourcesContent":["import * as React from 'react'\n  /* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\n\nimport DefaultLayout from \"/home/runner/work/vaccine-solution-main/vaccine-solution-main/docs/node_modules/gatsby-theme-carbon/src/templates/Default.js\";\nexport const _frontmatter = {};\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = DefaultLayout;\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n\n    <h3>{`An alternate approach is to setup a CI/CD pipeline`}</h3>\n    <p>{`We have adopted the Git Action to manage the `}<a parentName=\"p\" {...{\n        \"href\": \"https://github.com/ibm-cloud-architecture/refarch-kc-gitops/blob/master/KContainer-CI-Strategy.md\"\n      }}>{`continuous integration`}</a>{`, and ArgoCD for the continuous deployment. The build process will build the following images:`}</p>\n    <ul>\n      <li parentName=\"ul\">{`[https://hub.docker.com/repository/docker/ibmcase/kcontainer-reefer-simulator]`}</li>\n    </ul>\n    <p>{`Helm charts are added for the simulator and the scoring agent, using `}<inlineCode parentName=\"p\">{`helm create`}</inlineCode>{` command, and then the values.yaml and deployment.yaml files were updated to set environment variables and other parameters.`}</p>\n    <h2>{`Test sending a simulation control to the POST api`}</h2>\n    <p>{`The script `}<inlineCode parentName=\"p\">{`sendSimulControl.sh`}</inlineCode>{` is used for that. The usage looks like:  `}<inlineCode parentName=\"p\">{`sendSimulControl.sh hostname simultype (co2sensor | o2sensor | poweroff) containerID nb_of_records`}</inlineCode></p>\n    <pre><code parentName=\"pre\" {...{}}>{`pwd\nrefarch-reefer-ml\n./scripts/sendSimulControl.sh reefersimulatorroute-reefershipmentsolution.apps.green-with-envy.ocp.csplab.local co2sensor C01 2000\n`}</code></pre>\n    <p>{`If you use no argument for this script, it will send co2sensor control to the service running on our openshift cluster on IBM Cloud.`}</p>\n    <p>{`Looking at the logs from the pod using `}<inlineCode parentName=\"p\">{`oc logs reefersimulator-3-jdh2v`}</inlineCode>{` you can see something like:`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`     \"POST /order HTTP/1.1\" 404 232 \"-\" \"curl/7.54.0\"\n    {'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 10, 'good_temperature': 4.4}\n    Generating  10  Co2 metrics\n`}</code></pre>\n    <p>{`We will see how those events are processed in the next section.`}</p>\n    <h2>{`The predictive scoring agent`}</h2>\n    <p>{`Applying the same pattern as the simulation webapp, we implement a kafka consumer and producer in python that calls the serialized analytical model. The code in the `}<inlineCode parentName=\"p\">{`scoring\\\\eventConsumer`}</inlineCode>{` folder.`}</p>\n    <p>{`Applying a TDD approach we start by a TestScoring.py class.`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`import unittest\nfrom domain.predictservice import PredictService\n\nclass TestScoreMetric(unittest.TestCase):\n    def testCreation(self):\n        serv = PredictService\n        \nif __name__ == '__main__':\n    unittest.main()\n`}</code></pre>\n    <p>{`Use the same python environment with docker:`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`./startPythonEnv\nroot@1de81b16f940:/# export PYTHONPATH=/home/scoring/eventConsumer\nroot@1de81b16f940:/# cd /home/scoring/eventConsumer\nroot@1de81b16f940:/home/scoring/eventConsumer# python tests/TestScoring.py \n`}</code></pre>\n    <p>{`Test fails, so let add the scoring service with a constructor, and load the serialized pickle model (which was copied from the ml folder).`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`import pickle\n\nclass PredictService:\n    def __init__(self,filename = \"domain/model_logistic_regression.pkl\"):\n        self.model = pickle.load(open(filename,\"rb\"),encoding='latin1')\n    \n    \n    def predict(self,metricEvent):\n        TESTDATA = StringIO(metricEvent)\n        data = pd.read_csv(TESTDATA, sep=\",\")\n        data.columns = data.columns.to_series().apply(lambda x: x.strip())\n        X = data[ X = data[FEATURES_NAMES]]\n        return self.model.predict(X)\n    \n`}</code></pre>\n    <p>{`Next we need to test a predict on an event formated as a csv string. The test looks like:`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`    serv = PredictService()\n    header=\"\"\"Timestamp, ID, Temperature(celsius), Target_Temperature(celsius), Power, PowerConsumption, ContentType, O2, CO2, Time_Door_Open, Maintenance_Required, Defrost_Cycle\"\"\"\n    event=\"2019-04-01 T16:29 Z,1813, 101, 4.291843460900875,4.4,0,10.273342381017777,3,4334.920958996634,4.9631508046318755,1,0,6\"\"\"\n    record=header+\"\\\\n\"+event\n    print(serv.predict(record))\n`}</code></pre>\n    <p>{`So the scoring works, now we need to code the scoring application that will be deployed to Openshift cluster, and which acts as a consumer of container metrics events and a producer container events. `}</p>\n    <p>{`The Scoring Agent code of this app is `}<a parentName=\"p\" {...{\n        \"href\": \"https://github.com/ibm-cloud-architecture/refarch-reefer-ml/blob/master/scoring/ScoringAgent.py\"\n      }}>{`ScoringAgent.py`}</a>{` module. It starts a consumer to get messages from Kafka. And when a message is received, it needs to do some data extraction and transformation and then use the predictive service.`}</p>\n    <p>{`During the tests we have issue in the data quality, so it is always a good practice to add a validation function to assess if all the records are good. For production, this code needs to be enhanced for better error handling an reporting.`}</p>\n    <h3>{`Run locally`}</h3>\n    <p>{`Under `}<inlineCode parentName=\"p\">{`scoring\\\\eventConsumer`}</inlineCode>{` folder, set the environment variables for KAFKA using the commands below: (It uses event streams on IBM Cloud)`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`export KAFKA_BROKERS=broker-3.eventstreams.cloud.ibm.com:9093,broker-1.eventstreams.cloud.ibm.com:9093,broker-0.eventstreams.cloud.ibm.com:9093,broker-5.eventstreams.cloud.ibm.com:9093,broker-2.eventstreams.cloud.ibm.com:9093,broker-4.eventstreams.cloud.ibm.com:9093\nexport KAFKA_APIKEY=\"set-api-key-for-eventstreams-on-cloud\"\n\ndocker run -e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_APIKEY=$KAFKA_APIKEY  -v $(pwd)/..:/home -ti ibmcase/python bash -c \"cd /home/scoring && export PYTHONPATH=/home && python ScoringAgent.py\"\n`}</code></pre>\n    <h3>{`Scoring: Build and run on Openshift`}</h3>\n    <p>{`The first time we need to add the application to the existing project, run the following command:`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`oc new-app python:latest~https://github.com/ibm-cloud-architecture/refarch-reefer-ml.git --context-dir=scoring/eventConsumer --name reeferpredictivescoring\n`}</code></pre>\n    <p>{`This command will run a source to image, build all the needed yaml files for the kubernetes deployment and start the application in a pod. It use the `}<inlineCode parentName=\"p\">{`--context`}</inlineCode>{` flag to define what to build and run. With this capability we can use the same github repository for different sub component.`}</p>\n    <p>{`As done for simulator, the scoring service needs environment variables. We can set them using the commands`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`oc set env dc/reeferpredictivescoring KAFKA_BROKERS=$KAFKA_BROKERS\noc set env dc/reeferpredictivescoring KAFKA_APIKEY=$KAFKA_APIKEY\noc set env dc/reeferpredictivescoring KAFKA_CERT=/opt/app-root/src/es-cert.pem\n`}</code></pre>\n    <p>{`but we have added a script for you to do so. This script needs only to be run at the first deployment. It leverage the common setenv scripts:`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`../scripts/defEnvVarInOpenShift.sh \n`}</code></pre>\n    <p>{`The list of running pods should show the build pods for this application:`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{` oc get pods\n reeferpredictivescoring-1-build   1/1       Running      0          24s\n`}</code></pre>\n    <p>{`To run the build again after commit code to github:`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`oc start-build reeferpredictivescoring \n\n# or from local file system\noc start-build reeferpredictivescoring --from-file=.\n`}</code></pre>\n    <p>{`To see the log:`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{` oc logs reeferpredictivescoring-2-rxr6j\n`}</code></pre>\n    <p>{`To be able to run on Openshift, the APP_FILE environment variable has to be set to ScoringApp.py. This can be done in the `}<inlineCode parentName=\"p\">{`environment`}</inlineCode>{` file under the `}<inlineCode parentName=\"p\">{`.s2i `}</inlineCode>{` folder.`}</p>\n    <p>{`The scoring service has no API exposed to the external world, so we do not need to create a `}<inlineCode parentName=\"p\">{`Route`}</inlineCode>{` or ingress.`}</p>\n    <p>{`See the `}<a parentName=\"p\" {...{\n        \"href\": \"#integration-tests\"\n      }}>{`integration test`}</a>{` section to see a demonstration of the solution end to end.`}</p>\n    <h3>{`Build docker images`}</h3>\n    <p>{`For the scoring agent:`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`# scoring folder\n\n`}</code></pre>\n    <h4>{`Run kafka on your laptop`}</h4>\n    <p>{`For development purpose, you can also run kafka, zookeeper and postgresql and the solution on your laptop. For that read `}<a parentName=\"p\" {...{\n        \"href\": \"https://github.com/ibm-cloud-architecture/refarch-reefer-ml/blob/master/docker/README.md\"\n      }}>{`this readme`}</a>{` for details.`}</p>\n\n    </MDXLayout>;\n}\n;\nMDXContent.isMDXComponent = true;\n      "],"sourceRoot":""}