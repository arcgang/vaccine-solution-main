{"version":3,"sources":["webpack:///./src/pages/solution/cp4d/mdlc-anatomy.mdx"],"names":["_frontmatter","layoutProps","MDXLayout","DefaultLayout","MDXContent","components","props","mdxType","parentName","isMDXComponent"],"mappings":"yeAMO,IAAMA,EAAe,GAOtBC,EAAc,CAClBD,gBAEIE,EAAYC,IACH,SAASC,EAAT,GAGZ,IAFDC,EAEC,EAFDA,WACGC,E,oIACF,mBACD,OAAO,YAACJ,EAAD,KAAeD,EAAiBK,EAAhC,CAAuCD,WAAYA,EAAYE,QAAQ,cAG5E,4WACA,qBAAG,sBAAQC,WAAW,KAAnB,kDACH,4CACA,sBACE,kBAAIA,WAAW,MAAf,gFACA,kBAAIA,WAAW,MAAf,kHACA,kBAAIA,WAAW,MAAf,+GACA,kBAAIA,WAAW,MAAf,kIACA,kBAAIA,WAAW,MAAf,6BAEF,0CACA,gLAEA,qBAAG,sBAAQA,WAAW,KAAnB,yEACH,iDACA,+oBAMA,0CACA,gQAEA,8CACA,iyBAMA,0CACA,uQAMJJ,EAAWK,gBAAiB","file":"component---src-pages-solution-cp-4-d-mdlc-anatomy-mdx-9bb3e28cf2c10289de51.js","sourcesContent":["import * as React from 'react'\n  /* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nimport DefaultLayout from \"/home/runner/work/vaccine-solution-main/vaccine-solution-main/docs/node_modules/gatsby-theme-carbon/src/templates/Default.js\";\nexport const _frontmatter = {};\n\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n  return <div {...props} />;\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = DefaultLayout;\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n\n    <p>{`In this section has step by step guidance on how to develop and deploy a model using a simple Model Development Lifecycle Workflow with Governance in Cloud Pak For Data. We show here a very basic workflow. The workflow can be made as complex as needed with sub-workflow with more manual and system controlled gates as needed by a customer.`}</p>\n    <p><strong parentName=\"p\">{`Step 1 : Initiate Model Development Lifecycle`}</strong></p>\n    <p>{`Role - ModelManager`}</p>\n    <ol>\n      <li parentName=\"ol\">{`Login to OpenPages. Create a Model in OpenPages and assign it Proposed stage`}</li>\n      <li parentName=\"ol\">{`Provide Description with Modelâ€™s details. Additional Description with Model purpose, Data Sources to be used. `}</li>\n      <li parentName=\"ol\">{`Select Yes for the fields Machine Learning Model, Monitored With OpenScale. Select Yes for Usability Status`}</li>\n      <li parentName=\"ol\">{`Create a Catalog for the model in Watson Knowledge Catalog. Provide the name and link of the Catalog in the respective fields.`}</li>\n      <li parentName=\"ol\">{`Save the Model Workflow.`}</li>\n    </ol>\n    <p>{`Role - ModelOwner`}</p>\n    <p>{`f. Login to OpenPages. Go to the Model. Review the Model Deatils\ng. Change the model status to Approved for Data Acquisition. Save the Model Workflow.`}</p>\n    <p><strong parentName=\"p\">{`Step 2 : Data Acquizition, Feature Engineering and Model Development`}</strong></p>\n    <p>{`Role - ModelDataEnginner`}</p>\n    <p>{`a. Login to OpenPages. Get Model details. Get Catalog name. Get Data Asset name.\nb. Create a Analytics Project in Cloud Pak For Data\nc. To the project add the Notebook provided for acquiring Data from Kafka in Clous Pak For Integration\nd. Run the Notebook. It will generate the data in a csv file.\ne. Publish the CSV file to Catalog designated for the Model - give the Data Asset an appropriate name. Also publish the Notebook to the Catalog.\nf. Go to the OpenPages. Update the name of the Raw Data Asset published to the Catalog to the appropriate field of the Catalog. Change the Model Status to Data Acquisition Completed.`}</p>\n    <p>{`Role - ModelOwner`}</p>\n    <p>{`g. Login to OpenPages. Go to the Model. Check the name of the Data Asset for model development. Go to the Catalog. Review the Raw Data Asset.\nh. Change the model status to Approved for Feature Engineering. Save the Model Workflow.`}</p>\n    <p>{`Role - ModelDeveloper`}</p>\n    <p>{`a. Login to OpenPages. Get Model details. Get Catalog name.\nb. Create a Analytics Project in Cloud Pak For Data\nc. To the project add the Data Asset from the Catalog.\nd. Use Refinery to do the feature engineering as provided in the Solution section. Add the Anomaly Flag. Alyternatively one can use Notebooks or SPSS Modleer for the Feature Engineering.\ne. Publish the Feature Engineered Data to Catalog. Give the Data Asset an appropriate name and tag it appropriately. Also publish the Data Refinery Flow (export from project and import as data asset) to the Catalog.\nf. Go to the OpenPages. Update the name of the Featured Engineered Data Asset published to the Catalog to the appropriate field of the Catalog. Change the Model Status to Feature Engineering Completed.`}</p>\n    <p>{`Role - ModelOwner`}</p>\n    <p>{`g. Login to OpenPages. Go to the Model. Check the name of the Feature Engineered Data Asset for model development. Go to the Catalog. Review the Data Asset\nh. Change the model status to Approved for Development. Save the Model Workflow.`}</p>\n\n    </MDXLayout>;\n}\n;\nMDXContent.isMDXComponent = true;\n      "],"sourceRoot":""}