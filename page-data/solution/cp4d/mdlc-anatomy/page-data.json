{"componentChunkName":"component---src-pages-solution-cp-4-d-mdlc-anatomy-mdx","path":"/solution/cp4d/mdlc-anatomy/","result":{"pageContext":{"frontmatter":{"title":"IBM Cloud Pak for Data - Model Lifecycle Governance","description":"IBM Cloud Pak for Data - Model Lifecycle Governance using OpenPages"},"relativePagePath":"/solution/cp4d/mdlc-anatomy.mdx","titleType":"append","MdxNode":{"id":"824eac71-f78a-5953-b005-1892842ea7fe","children":[],"parent":"1d787ea3-54aa-53bd-a38f-231affab9f1c","internal":{"content":"---\ntitle: IBM Cloud Pak for Data - Model Lifecycle Governance\ndescription: IBM Cloud Pak for Data - Model Lifecycle Governance using OpenPages\n---\n\nIn this section has step by step guidance on how to develop and deploy a model using a simple Model Development Lifecycle Workflow with Governance in Cloud Pak For Data. We show here a very basic workflow. The workflow can be made as complex as needed with sub-workflow with more manual and system controlled gates as needed by a customer.\n\n__Step 1 : Initiate Model Development Lifecycle__\n\n\nRole - ModelManager\n\n1. Login to OpenPages. Create a Model in OpenPages and assign it Proposed stage\n2. Provide Description with Model's details. Additional Description with Model purpose, Data Sources to be used. \n3. Select Yes for the fields Machine Learning Model, Monitored With OpenScale. Select Yes for Usability Status\n4. Create a Catalog for the model in Watson Knowledge Catalog. Provide the name and link of the Catalog in the respective fields.\n5. Save the Model Workflow.\n\nRole - ModelOwner\n\n6. Login to OpenPages. Go to the Model. Review the Model Deatils\n7. Change the model status to Approved for Data Acquisition. Save the Model Workflow.\n\n__Step 2 : Data Acquizition, Feature Engineering and Model Development__\n\nRole - ModelDataEnginner\n\n1. Login to OpenPages. Get Model details. Get Catalog name. Get Data Asset name.\n2. Create a Analytics Project in Cloud Pak For Data\n3. To the project add the Notebook provided for acquiring Data from Kafka in Clous Pak For Integration\n4. Run the Notebook. It will generate the data in a csv file. \n5. Publish the CSV file to Catalog designated for the Model - give the Data Asset an appropriate name. Also publish the Notebook to the Catalog.\n6. Go to the OpenPages. Update the name of the Raw Data Asset published to the Catalog to the appropriate field of the Catalog. Change the Model Status to Data Acquisition Completed.\n\nRole - ModelOwner\n\n7. Login to OpenPages. Go to the Model. Check the name of the Data Asset for model development. Go to the Catalog. Review the Raw Data Asset.\n8. Change the model status to Approved for Feature Engineering. Save the Model Workflow.\n\nRole - ModelDeveloper\n\n9. Login to OpenPages. Get Model details. Get Catalog name.\n10. Create a Analytics Project in Cloud Pak For Data\n11. To the project add the Raw Data Asset from the Catalog. \n12. Use Refinery to do the feature engineering based on the instructions provided in the Solution section. Add the Anomaly Flag. Alternatively one can use Notebooks or SPSS Modleer for the Feature Engineering.\n13. Publish the Feature Engineered Data to Catalog. Create Related Asset for the Feature Engineered Data Asset in the Catalog pointing it to the Raw Data Asset. Also publish the Data Refinery Flow (export from project and import as data asset) to the Catalog.\n14. Go to the OpenPages. Update the name of the Featured Engineered Data Asset published to the Catalog to the appropriate field of the Catalog. Change the Model Status to Feature Engineering Completed.\n\nRole - ModelOwner\n\n15. Login to OpenPages. Go to the Model. Check the name of the Feature Engineered Data Asset for model development. Go to the Catalog. Review the Feature Engineered Data Asset\n16. Change the model status to Approved for Development. Save the Model Workflow.\n\nRole - ModelDeveloper\n\n17. Login to OpenPages. Get Model details. Get Catalog name.\n10. Create a Analytics Project in Cloud Pak For Data\n11. To the project add the Feature Enfgineered Data Asset from the Catalog. \n12. Use Auto AI to create thye model based on the instructions provided in the Solution section. Alternatively one can use Notebooks or SPSS Modleer for the Model Development.\n13. Publish the Model Asset to Catalog. Create Related Asset for the Model in the Catalog pointing it to the Feature Engineered Data Asset . Also publish the Notebook (generated from Auto AI) that is used to create the model to the Catalog.\n14. Go to the OpenPages. Update the name of the Model Asset published to the Catalog to the appropriate field of the Catalog. Change the Model Status to Model Development Completed.\n\nRole - ModelOwner\n\n15. Login to OpenPages. Go to the Model. Check the name of Model Asset. Go to the Catalog. Review the Model Data Asset\n16. Change the model status to Approved for Validation. Save the Model Workflow.\n\nRole - ModelValidator\n\n17. Login to OpenPages. Get Model details. Get Catalog name. Get Model Asset name.\n18. Create a Analytics Project in Cloud Pak For Data for Model Validation.\n19. To the project add the Model Asset from the Catalog. \n20. Create a Deployment Space for deploying the model for Validation. Associate the Deployment Space to the Validation Project. Ptomote Model Asset from project to that Deployment Space.\n21. Create Online Deployment of the Model. Configure the Deployment in OpenScale for Validation using pre-production deployment space. \n22. Create a Validation Dataset. Use the same in OpenScale to validate the Model. Generate the Validation Report from OpenScale.\n13. Publish the Validation Data Asset to Catalog. Download Model Validation Report and upload the same to Catalog. \n14. Go to the OpenPages. Update the name of the Validation Data Asset published to the Catalog to the appropriate field of the Catalog. Also update the name of the Validation Report. Change the Model Status to Model Validation Completed.\n\nRole - ModelOwner\n\n15. Login to OpenPages. Go to the Model. Check the name of Validation Data Asset and Validation Repor. Go to the Catalog. Review those assets.\n16. Change the model status to Approved for Deployment. Save the Model Workflow.\n\n","type":"Mdx","contentDigest":"e5299f3d9faaf640db1d4aceed354c53","counter":264,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"IBM Cloud Pak for Data - Model Lifecycle Governance","description":"IBM Cloud Pak for Data - Model Lifecycle Governance using OpenPages"},"exports":{},"rawBody":"---\ntitle: IBM Cloud Pak for Data - Model Lifecycle Governance\ndescription: IBM Cloud Pak for Data - Model Lifecycle Governance using OpenPages\n---\n\nIn this section has step by step guidance on how to develop and deploy a model using a simple Model Development Lifecycle Workflow with Governance in Cloud Pak For Data. We show here a very basic workflow. The workflow can be made as complex as needed with sub-workflow with more manual and system controlled gates as needed by a customer.\n\n__Step 1 : Initiate Model Development Lifecycle__\n\n\nRole - ModelManager\n\n1. Login to OpenPages. Create a Model in OpenPages and assign it Proposed stage\n2. Provide Description with Model's details. Additional Description with Model purpose, Data Sources to be used. \n3. Select Yes for the fields Machine Learning Model, Monitored With OpenScale. Select Yes for Usability Status\n4. Create a Catalog for the model in Watson Knowledge Catalog. Provide the name and link of the Catalog in the respective fields.\n5. Save the Model Workflow.\n\nRole - ModelOwner\n\n6. Login to OpenPages. Go to the Model. Review the Model Deatils\n7. Change the model status to Approved for Data Acquisition. Save the Model Workflow.\n\n__Step 2 : Data Acquizition, Feature Engineering and Model Development__\n\nRole - ModelDataEnginner\n\n1. Login to OpenPages. Get Model details. Get Catalog name. Get Data Asset name.\n2. Create a Analytics Project in Cloud Pak For Data\n3. To the project add the Notebook provided for acquiring Data from Kafka in Clous Pak For Integration\n4. Run the Notebook. It will generate the data in a csv file. \n5. Publish the CSV file to Catalog designated for the Model - give the Data Asset an appropriate name. Also publish the Notebook to the Catalog.\n6. Go to the OpenPages. Update the name of the Raw Data Asset published to the Catalog to the appropriate field of the Catalog. Change the Model Status to Data Acquisition Completed.\n\nRole - ModelOwner\n\n7. Login to OpenPages. Go to the Model. Check the name of the Data Asset for model development. Go to the Catalog. Review the Raw Data Asset.\n8. Change the model status to Approved for Feature Engineering. Save the Model Workflow.\n\nRole - ModelDeveloper\n\n9. Login to OpenPages. Get Model details. Get Catalog name.\n10. Create a Analytics Project in Cloud Pak For Data\n11. To the project add the Raw Data Asset from the Catalog. \n12. Use Refinery to do the feature engineering based on the instructions provided in the Solution section. Add the Anomaly Flag. Alternatively one can use Notebooks or SPSS Modleer for the Feature Engineering.\n13. Publish the Feature Engineered Data to Catalog. Create Related Asset for the Feature Engineered Data Asset in the Catalog pointing it to the Raw Data Asset. Also publish the Data Refinery Flow (export from project and import as data asset) to the Catalog.\n14. Go to the OpenPages. Update the name of the Featured Engineered Data Asset published to the Catalog to the appropriate field of the Catalog. Change the Model Status to Feature Engineering Completed.\n\nRole - ModelOwner\n\n15. Login to OpenPages. Go to the Model. Check the name of the Feature Engineered Data Asset for model development. Go to the Catalog. Review the Feature Engineered Data Asset\n16. Change the model status to Approved for Development. Save the Model Workflow.\n\nRole - ModelDeveloper\n\n17. Login to OpenPages. Get Model details. Get Catalog name.\n10. Create a Analytics Project in Cloud Pak For Data\n11. To the project add the Feature Enfgineered Data Asset from the Catalog. \n12. Use Auto AI to create thye model based on the instructions provided in the Solution section. Alternatively one can use Notebooks or SPSS Modleer for the Model Development.\n13. Publish the Model Asset to Catalog. Create Related Asset for the Model in the Catalog pointing it to the Feature Engineered Data Asset . Also publish the Notebook (generated from Auto AI) that is used to create the model to the Catalog.\n14. Go to the OpenPages. Update the name of the Model Asset published to the Catalog to the appropriate field of the Catalog. Change the Model Status to Model Development Completed.\n\nRole - ModelOwner\n\n15. Login to OpenPages. Go to the Model. Check the name of Model Asset. Go to the Catalog. Review the Model Data Asset\n16. Change the model status to Approved for Validation. Save the Model Workflow.\n\nRole - ModelValidator\n\n17. Login to OpenPages. Get Model details. Get Catalog name. Get Model Asset name.\n18. Create a Analytics Project in Cloud Pak For Data for Model Validation.\n19. To the project add the Model Asset from the Catalog. \n20. Create a Deployment Space for deploying the model for Validation. Associate the Deployment Space to the Validation Project. Ptomote Model Asset from project to that Deployment Space.\n21. Create Online Deployment of the Model. Configure the Deployment in OpenScale for Validation using pre-production deployment space. \n22. Create a Validation Dataset. Use the same in OpenScale to validate the Model. Generate the Validation Report from OpenScale.\n13. Publish the Validation Data Asset to Catalog. Download Model Validation Report and upload the same to Catalog. \n14. Go to the OpenPages. Update the name of the Validation Data Asset published to the Catalog to the appropriate field of the Catalog. Also update the name of the Validation Report. Change the Model Status to Model Validation Completed.\n\nRole - ModelOwner\n\n15. Login to OpenPages. Go to the Model. Check the name of Validation Data Asset and Validation Repor. Go to the Catalog. Review those assets.\n16. Change the model status to Approved for Deployment. Save the Model Workflow.\n\n","fileAbsolutePath":"/home/runner/work/vaccine-solution-main/vaccine-solution-main/docs/src/pages/solution/cp4d/mdlc-anatomy.mdx"}}}}