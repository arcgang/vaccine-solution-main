{"componentChunkName":"component---src-pages-use-cases-cold-chain-index-mdx","path":"/use-cases/cold-chain/","result":{"pageContext":{"frontmatter":{"title":"Cold-chain monitoring","description":"Cold-chain monitoring"},"relativePagePath":"/use-cases/cold-chain/index.mdx","titleType":"append","MdxNode":{"id":"c6897775-71a8-56a6-bcb0-4f67274e7c34","children":[],"parent":"5c1ac8d6-806f-50f3-aae8-6be814af7df0","internal":{"content":"---\ntitle: Cold-chain monitoring\ndescription: Cold-chain monitoring\n---\n\nThe vaccine lots need to be kept at a constant temperature for a period of time. The sensor telemetry data coming from the refrigerated shipping containers is processed to assess cold-chain violations.\n\nThe solution for this use case includes streaming telemetry events, a stateful microservice to implement aggregation & alarm generation, and integration with a microservice to log issues against the refrigerated shipping container.\n\n## Components involved in this use case\n\n* [Vaccine Refrigerator container Simulator](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator)\n* [Vaccine Reefer Monitoring Agent](https://github.com/ibm-cloud-architecture/vaccine-monitoring-agent)\n* [IBM Event Streams](https://ibm.github.io/event-streams/)\n* [Anomaly detection scoring service](/analyze/ws-ml-dev/) with WatsonML and anomaly detection built in Cloud Pak for Data\n\n![](./images/cc-components.png)\n\n*The reefer manager is not done yet*\n\n## Understand the components\n\n* The Reefer simulator is a python  Flask app, which supports simple API to control the Refrigerator container simulation . It is described in [this note](/solution/reefer-iot/), also see next section to deploy it on OpenShift.\n* The Monitoring Agent is a Quarkus app, with Kafka Streams, reactive messaging to monitor the cold chain with stateful operations. It also call the Anomaly detection service. Implementation details can be read in [this note](/solution/cold-monitoring/).\n* The model to assess if the refrigerator container has issue. To develop the model we need to [get the telemetry data](/solution/cp4d/) in Cloud Pak for data, and then perform feature engineering and use AutoAI for developing the model as described in [this note](/analyze/ws-ml-dev/). As an alternate to collect the data, it is possible to directly [integrate with Kafka topic](/solution/cp4d/eventStream/) and then save then as csv or in a datalake.\n\n## Run on OpenShift\n\n### Prerequsites\n\n1. Create the following artifacts in the `eventstreams` namespace on your OpenShift cluster:\n\n   1. Create an EventStreams instance _(via the [Event Streams Custom Resource](https://ibm.github.io/event-streams/installing/installing/#install-an-event-streams-instance))_.\n   2. Create a [Kafka User with SCRAM-based credentials](https://ibm.github.io/event-streams/security/managing-access/#managing-access-to-kafka-resources), as required by the [Vaccine Reefer Simulator](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator#application-deployment).\n   3. Create a [Kafka User with TLS-based credentials](https://ibm.github.io/event-streams/security/managing-access/#managing-access-to-kafka-resources), as required by the [Vaccine Monitoring Agent](https://github.com/ibm-cloud-architecture/vaccine-monitoring-agent#create-a-tls-user).\n   4. Create two [Kafka Topics](https://ibm.github.io/event-streams/getting-started/creating-topics/). This tutorial will assume the names of `coldchain-telemetry` and `coldchain-reefers` respectively.\n\n2. Create a new project named `coldchain` that will be used for the deployment of all other components.\n3. The [Appsody Operator](https://operatorhub.io/operator/appsody-operator) is deployed to manage all namespaces on the OpenShift cluster.\n4. [OpenShift CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-cli) on your local environment.\n5. [jq](https://stedolan.github.io/jq/) on your local environment.\n\n### Deploy the Vaccine Reefer Simulator\n\nTo get more detail of this Python Flask application [read this note](/solution/reefer-iot/).\n\n1. Ensure you are working inside the correct project via the following `oc` command:\n\n  ```shell\n  oc project coldchain\n  ```\n\n2. Export the value of your Event Streams cluster name into an environment variable:\n\n  ```shell\n  export CLUSTER_NAME=development\n  ```\n\n3. Create a ConfigMap named `reefer-simul-cm` with the following `oc` command:\n\n  ```shell\n  oc create configmap reefer-simul-cm \\\n  --from-literal=KAFKA_CERT=/app/certs/ca.crt \\\n  --from-literal=KAFKA_MAIN_TOPIC=coldchain-telemetry \\\n  --from-literal=KAFKA_BROKERS=___kafka-kafka-bootstrap-eventstreams.cluster.appdomain.cloud:443___\n  ```\n   - Replacing the value of `KAFKA_BROKERS` above with the **External** cluster bootstrap address presented to you during the creation of your SCRAM-based KafkaUser.\n   - This value can be accessed via the following `oc` command:\n    ```shell\n    oc get route -n eventstreams ${CLUSTER_NAME}-kafka-bootstrap -o jsonpath=\"{.status.ingress[0].host}:443\"\n    ```\n\n4. Create a Secret named `reefer-simul-secret` with the following `oc` command:\n\n  ```shell\n  oc create secret generic reefer-simul-secret \\\n  --from-literal=KAFKA_USER=___your-scram-based-kafka-user-name___ \\\n  --from-literal=KAFKA_PASSWORD=___your-scram-based-kafka-user-password___\n  ```\n   - Replacing the values above with the values generated during the creation of your SCRAM-based KafkaUser.\n\n5. Copy the server-side public certificate of the Event Streams instance to your local project:\n\n  ```shell\n  oc get secret ${CLUSTER_NAME}-cluster-ca-cert -n eventstreams -o json | jq -r '.metadata.name=\"kafka-cluster-ca-cert\"' |jq -r '.metadata.namespace=\"coldchain\"' | oc apply -f -\n  ```\n   - Note that we are copying and renaming the certificate in a single command to minimize the need for editing deployment documents.\n\n6. Deploy the microservice components via the following `oc apply` command:\n\n  ```shell\n  oc apply -f https://raw.githubusercontent.com/ibm-cloud-architecture/vaccine-reefer-simulator/master/config/app-deployment.yaml\n  ```\n\n  You can verify the deployment state with the following:\n\n  ```shell\n  oc get pods -w\n  ```\n\nor the via the Openshift console:\n\n![2](./images/simul-app-ocp.png)\n\n\n### Deploy the Vaccine Monitoring Agent\n\nTo get more detail of this Java Quarkus microprofile application [read this note](/solution/cold-monitoring/). The project repository is [https://github.com/ibm-cloud-architecture/vaccine-monitoring-agent](https://github.com/ibm-cloud-architecture/vaccine-monitoring-agent)\n\n\n1. Ensure you are working inside the correct project via the following `oc` command:\n\n  ```shell\n  oc project coldchain\n  ```\n \n1. If not done so already, copy the server-side public certificate of the Event Streams instance to your local project:\n\n  ```shell\n  oc get secret ${CLUSTER_NAME}-cluster-ca-cert -n eventstreams --export -o json | jq -r '.metadata.name=\"kafka-cluster-ca-cert\"' | oc apply -f -\n  ```\n   - Note that we are copying and renaming the certificate in a single command to minimize the need for editing deployment documents.\n\n1. Copy your TLS-based KafkaUser's credentials to the local namespace with the following `oc` command:\n\n  ```shell\n  oc get secret -n eventstreams ${TLS_USER} -o json --export | jq -r '.metadata.name=\"kafka-user\"' | oc apply -f -\n  ```\n    - Note that we are copying and renaming the credentials in a single command to minimize the need for editing deployment documents.\n2. Export the value of your Event Streams cluster name and TLS-based KafkaUser into environment variables:\n\n  ```shell\n  export CLUSTER_NAME=development\n  export TLS_USER=___your-tls-based-kafka-user-name___\n  export YOUR_SUFFIX=___a_unique_identifier_for_your_application___\n  ```\n\n1. If you use the Anomaly detection service deployed in Watson ML:\n\n   * Get user credential to access to cloud pack for data, with the API key.\n   * Get the ANOMALY_DETECTION_URL\n   * Get the CP4D_AUTH_URL used to get access token\n\n  You will use those values in the config map of this application.\n\n3. Create a ConfigMap named `agent-cm` (see exising one [here](https://github.com/ibm-cloud-architecture/vaccine-monitoring-agent/blob/master/src/main/kubernetes/configmap.yaml)) with the following `oc` command:\n\n ```shell\n  # USE this if you do not use the anomaly detection service\n  oc create configmap agent-cm \\\n  --from-literal=KAFKA_USER=app-tls \\\n  --from-literal=reefer-topic=coldchain-reefers \\\n  --from-literal=telemetry-topic=coldchain-telemetry \\\n  --from-literal=KAFKA_BOOTSTRAP_SERVERS=${CLUSTER_NAME}-kafka-bootstrap.eventstreams.svc:9093 \\\n  --from-literal=QUARKUS_KAFKA_STREAMS_APPLICATION_ID=cold-chain-agent-${YOUR_SUFFIX} \\\n  --from-literal=KAFKA_SASL_MECHANISM=SCRAM-SHA-512 \\\n  --from-literal=KAFKA_SECURITY_PROTOCOL=SASL_SSL\n  # USE the command below if you USE the anomaly detection service\n  oc create configmap agent-cm \\\n  --from-literal=reefer-topic=coldchain-reefers \\\n  --from-literal=telemetry-topic=coldchain-telemetry \\\n  --from-literal=KAFKA_BOOTSTRAP_SERVERS=${CLUSTER_NAME}-kafka-bootstrap.eventstreams.svc:9093 \\\n  --from-literal=QUARKUS_KAFKA_STREAMS_APPLICATION_ID=cold-chain-agent-${YOUR_SUFFIX} \\\n  --from-literal=KAFKA_SASL_MECHANISM=SCRAM-SHA-512 \\\n  --from-literal=KAFKA_SECURITY_PROTOCOL=SASL_SSL \\\n  --from-literal=CP4D_AUTH_URL=  \\\n  --from-literal=CP4D_USER: <cp4d user> \\\n  --from-literal=CP4D_AUTH_URL: \\\n  --from-literal=PREDICTION_ENABLED=true\n\n ```\n\n  The value of `telemetry-topic` should match the value used in the creation of the `reefer-simul-cmap` ConfigMap above.\n\n4. Define a secret with:\n\n  ```shell\n  oc create secret generic reefer-simul-secret \\\n  --from-literal=ANOMALY_DETECTION_URL=https://zen-cpd-ze.../predictions?version=2021-01-28 \\\n  --from-literal=KAFKA_USER=app-tls \\\n  --from-literal=KAFKA_PASSWORD=... \\\n    CP4D_USER: jboyer\n    CP4D_APIKEY: YdnIRC3WnuBziDvq98J00t4Crq8BtwsixwtKiALa\n    CP4D_AUTH_URL: https://zen-cpd-zen.apps.cpdv35-swat.cpd-daell.com/icp4d-api/v1/authorize\n  ```\n\n6. Deploy the microservice components via the following `oc apply` command:\n\n  ```shell\n  oc apply -f https://raw.githubusercontent.com/ibm-cloud-architecture/vaccine-monitoring-agent/master/src/main/kubernetes/openshift.yaml\n  ```\n\n  *The openshift.yaml is, in fact created using the `application.properties` and with the following command: `./mvnw clean package` and placed under `target/kubernetes`. We have copied this generated file for conveniance.* \n\n## Scenario script\n\nOnce the solution is up and running, execute the following steps to present an end-to-end demonstration:\n\n### Generate vaccine container telemetry events\n\n1. Access the Vaccine Reefer Simulator's Flasgger UI via the following `oc` command:\n\n   ```shell\n   oc get route vaccine-reefer-simulator -o jsonpath=\"http://{.status.ingress[0].host}\"\n   ```\n\n2. Expand the **POST `/control`** and click **Try it out**.\n\n3. In the **Edit Value** text box, update the values of the records accordingly:\n    * **containerID**: `C01`\n    * **nb_of_records**: `500`\n    * **product_id**: `covid-19`\n    * **simulation**: `temperature`\n\n4. Click **Execute**.\n\n### Analyze simulated reefer telemetry data\n\n1. Access the Event Streams Console UI via the following `oc` command:\n\n   ```shell\n   oc get route -n eventstreams ${CLUSTER_NAME}-ibm-es-ui -o jsonpath=\"https://{.status.ingress[0].host}\"\n   ```\n\n2. Click **Topics** from the left navigation menu and select the topic that matches the `KAFKA_MAIN_TOPIC` and `telemetry-topic` values.\n\n3. Explore the messages tab and the individual telemetry records emitted by the Vaccine Reefer Simulator component.\n\n### Analyze generated cold-chain violations\n\n1. Click **Topics** from the left navigation menu and selec the topic that matches the `reefer-topic` value.\n\n2. Explore the messages tab and the observed vaccine cold-chain violation alert events.\n\n3. The reefer container information contained in this topic have been identified as having observed temperatures outside the allowable range more than the allowable number of times, as determined to preserve the state of the vaccine doses contained.\n\n### Perform vaccine container maintenance\n\n<InlineNotification kind=\"warning\"><strong>TODO</strong> - SCORING</InlineNotification>\n","type":"Mdx","contentDigest":"e6912e4958c2c85f78158ccc569c3779","counter":274,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Cold-chain monitoring","description":"Cold-chain monitoring"},"exports":{},"rawBody":"---\ntitle: Cold-chain monitoring\ndescription: Cold-chain monitoring\n---\n\nThe vaccine lots need to be kept at a constant temperature for a period of time. The sensor telemetry data coming from the refrigerated shipping containers is processed to assess cold-chain violations.\n\nThe solution for this use case includes streaming telemetry events, a stateful microservice to implement aggregation & alarm generation, and integration with a microservice to log issues against the refrigerated shipping container.\n\n## Components involved in this use case\n\n* [Vaccine Refrigerator container Simulator](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator)\n* [Vaccine Reefer Monitoring Agent](https://github.com/ibm-cloud-architecture/vaccine-monitoring-agent)\n* [IBM Event Streams](https://ibm.github.io/event-streams/)\n* [Anomaly detection scoring service](/analyze/ws-ml-dev/) with WatsonML and anomaly detection built in Cloud Pak for Data\n\n![](./images/cc-components.png)\n\n*The reefer manager is not done yet*\n\n## Understand the components\n\n* The Reefer simulator is a python  Flask app, which supports simple API to control the Refrigerator container simulation . It is described in [this note](/solution/reefer-iot/), also see next section to deploy it on OpenShift.\n* The Monitoring Agent is a Quarkus app, with Kafka Streams, reactive messaging to monitor the cold chain with stateful operations. It also call the Anomaly detection service. Implementation details can be read in [this note](/solution/cold-monitoring/).\n* The model to assess if the refrigerator container has issue. To develop the model we need to [get the telemetry data](/solution/cp4d/) in Cloud Pak for data, and then perform feature engineering and use AutoAI for developing the model as described in [this note](/analyze/ws-ml-dev/). As an alternate to collect the data, it is possible to directly [integrate with Kafka topic](/solution/cp4d/eventStream/) and then save then as csv or in a datalake.\n\n## Run on OpenShift\n\n### Prerequsites\n\n1. Create the following artifacts in the `eventstreams` namespace on your OpenShift cluster:\n\n   1. Create an EventStreams instance _(via the [Event Streams Custom Resource](https://ibm.github.io/event-streams/installing/installing/#install-an-event-streams-instance))_.\n   2. Create a [Kafka User with SCRAM-based credentials](https://ibm.github.io/event-streams/security/managing-access/#managing-access-to-kafka-resources), as required by the [Vaccine Reefer Simulator](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator#application-deployment).\n   3. Create a [Kafka User with TLS-based credentials](https://ibm.github.io/event-streams/security/managing-access/#managing-access-to-kafka-resources), as required by the [Vaccine Monitoring Agent](https://github.com/ibm-cloud-architecture/vaccine-monitoring-agent#create-a-tls-user).\n   4. Create two [Kafka Topics](https://ibm.github.io/event-streams/getting-started/creating-topics/). This tutorial will assume the names of `coldchain-telemetry` and `coldchain-reefers` respectively.\n\n2. Create a new project named `coldchain` that will be used for the deployment of all other components.\n3. The [Appsody Operator](https://operatorhub.io/operator/appsody-operator) is deployed to manage all namespaces on the OpenShift cluster.\n4. [OpenShift CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-cli) on your local environment.\n5. [jq](https://stedolan.github.io/jq/) on your local environment.\n\n### Deploy the Vaccine Reefer Simulator\n\nTo get more detail of this Python Flask application [read this note](/solution/reefer-iot/).\n\n1. Ensure you are working inside the correct project via the following `oc` command:\n\n  ```shell\n  oc project coldchain\n  ```\n\n2. Export the value of your Event Streams cluster name into an environment variable:\n\n  ```shell\n  export CLUSTER_NAME=development\n  ```\n\n3. Create a ConfigMap named `reefer-simul-cm` with the following `oc` command:\n\n  ```shell\n  oc create configmap reefer-simul-cm \\\n  --from-literal=KAFKA_CERT=/app/certs/ca.crt \\\n  --from-literal=KAFKA_MAIN_TOPIC=coldchain-telemetry \\\n  --from-literal=KAFKA_BROKERS=___kafka-kafka-bootstrap-eventstreams.cluster.appdomain.cloud:443___\n  ```\n   - Replacing the value of `KAFKA_BROKERS` above with the **External** cluster bootstrap address presented to you during the creation of your SCRAM-based KafkaUser.\n   - This value can be accessed via the following `oc` command:\n    ```shell\n    oc get route -n eventstreams ${CLUSTER_NAME}-kafka-bootstrap -o jsonpath=\"{.status.ingress[0].host}:443\"\n    ```\n\n4. Create a Secret named `reefer-simul-secret` with the following `oc` command:\n\n  ```shell\n  oc create secret generic reefer-simul-secret \\\n  --from-literal=KAFKA_USER=___your-scram-based-kafka-user-name___ \\\n  --from-literal=KAFKA_PASSWORD=___your-scram-based-kafka-user-password___\n  ```\n   - Replacing the values above with the values generated during the creation of your SCRAM-based KafkaUser.\n\n5. Copy the server-side public certificate of the Event Streams instance to your local project:\n\n  ```shell\n  oc get secret ${CLUSTER_NAME}-cluster-ca-cert -n eventstreams -o json | jq -r '.metadata.name=\"kafka-cluster-ca-cert\"' |jq -r '.metadata.namespace=\"coldchain\"' | oc apply -f -\n  ```\n   - Note that we are copying and renaming the certificate in a single command to minimize the need for editing deployment documents.\n\n6. Deploy the microservice components via the following `oc apply` command:\n\n  ```shell\n  oc apply -f https://raw.githubusercontent.com/ibm-cloud-architecture/vaccine-reefer-simulator/master/config/app-deployment.yaml\n  ```\n\n  You can verify the deployment state with the following:\n\n  ```shell\n  oc get pods -w\n  ```\n\nor the via the Openshift console:\n\n![2](./images/simul-app-ocp.png)\n\n\n### Deploy the Vaccine Monitoring Agent\n\nTo get more detail of this Java Quarkus microprofile application [read this note](/solution/cold-monitoring/). The project repository is [https://github.com/ibm-cloud-architecture/vaccine-monitoring-agent](https://github.com/ibm-cloud-architecture/vaccine-monitoring-agent)\n\n\n1. Ensure you are working inside the correct project via the following `oc` command:\n\n  ```shell\n  oc project coldchain\n  ```\n \n1. If not done so already, copy the server-side public certificate of the Event Streams instance to your local project:\n\n  ```shell\n  oc get secret ${CLUSTER_NAME}-cluster-ca-cert -n eventstreams --export -o json | jq -r '.metadata.name=\"kafka-cluster-ca-cert\"' | oc apply -f -\n  ```\n   - Note that we are copying and renaming the certificate in a single command to minimize the need for editing deployment documents.\n\n1. Copy your TLS-based KafkaUser's credentials to the local namespace with the following `oc` command:\n\n  ```shell\n  oc get secret -n eventstreams ${TLS_USER} -o json --export | jq -r '.metadata.name=\"kafka-user\"' | oc apply -f -\n  ```\n    - Note that we are copying and renaming the credentials in a single command to minimize the need for editing deployment documents.\n2. Export the value of your Event Streams cluster name and TLS-based KafkaUser into environment variables:\n\n  ```shell\n  export CLUSTER_NAME=development\n  export TLS_USER=___your-tls-based-kafka-user-name___\n  export YOUR_SUFFIX=___a_unique_identifier_for_your_application___\n  ```\n\n1. If you use the Anomaly detection service deployed in Watson ML:\n\n   * Get user credential to access to cloud pack for data, with the API key.\n   * Get the ANOMALY_DETECTION_URL\n   * Get the CP4D_AUTH_URL used to get access token\n\n  You will use those values in the config map of this application.\n\n3. Create a ConfigMap named `agent-cm` (see exising one [here](https://github.com/ibm-cloud-architecture/vaccine-monitoring-agent/blob/master/src/main/kubernetes/configmap.yaml)) with the following `oc` command:\n\n ```shell\n  # USE this if you do not use the anomaly detection service\n  oc create configmap agent-cm \\\n  --from-literal=KAFKA_USER=app-tls \\\n  --from-literal=reefer-topic=coldchain-reefers \\\n  --from-literal=telemetry-topic=coldchain-telemetry \\\n  --from-literal=KAFKA_BOOTSTRAP_SERVERS=${CLUSTER_NAME}-kafka-bootstrap.eventstreams.svc:9093 \\\n  --from-literal=QUARKUS_KAFKA_STREAMS_APPLICATION_ID=cold-chain-agent-${YOUR_SUFFIX} \\\n  --from-literal=KAFKA_SASL_MECHANISM=SCRAM-SHA-512 \\\n  --from-literal=KAFKA_SECURITY_PROTOCOL=SASL_SSL\n  # USE the command below if you USE the anomaly detection service\n  oc create configmap agent-cm \\\n  --from-literal=reefer-topic=coldchain-reefers \\\n  --from-literal=telemetry-topic=coldchain-telemetry \\\n  --from-literal=KAFKA_BOOTSTRAP_SERVERS=${CLUSTER_NAME}-kafka-bootstrap.eventstreams.svc:9093 \\\n  --from-literal=QUARKUS_KAFKA_STREAMS_APPLICATION_ID=cold-chain-agent-${YOUR_SUFFIX} \\\n  --from-literal=KAFKA_SASL_MECHANISM=SCRAM-SHA-512 \\\n  --from-literal=KAFKA_SECURITY_PROTOCOL=SASL_SSL \\\n  --from-literal=CP4D_AUTH_URL=  \\\n  --from-literal=CP4D_USER: <cp4d user> \\\n  --from-literal=CP4D_AUTH_URL: \\\n  --from-literal=PREDICTION_ENABLED=true\n\n ```\n\n  The value of `telemetry-topic` should match the value used in the creation of the `reefer-simul-cmap` ConfigMap above.\n\n4. Define a secret with:\n\n  ```shell\n  oc create secret generic reefer-simul-secret \\\n  --from-literal=ANOMALY_DETECTION_URL=https://zen-cpd-ze.../predictions?version=2021-01-28 \\\n  --from-literal=KAFKA_USER=app-tls \\\n  --from-literal=KAFKA_PASSWORD=... \\\n    CP4D_USER: jboyer\n    CP4D_APIKEY: YdnIRC3WnuBziDvq98J00t4Crq8BtwsixwtKiALa\n    CP4D_AUTH_URL: https://zen-cpd-zen.apps.cpdv35-swat.cpd-daell.com/icp4d-api/v1/authorize\n  ```\n\n6. Deploy the microservice components via the following `oc apply` command:\n\n  ```shell\n  oc apply -f https://raw.githubusercontent.com/ibm-cloud-architecture/vaccine-monitoring-agent/master/src/main/kubernetes/openshift.yaml\n  ```\n\n  *The openshift.yaml is, in fact created using the `application.properties` and with the following command: `./mvnw clean package` and placed under `target/kubernetes`. We have copied this generated file for conveniance.* \n\n## Scenario script\n\nOnce the solution is up and running, execute the following steps to present an end-to-end demonstration:\n\n### Generate vaccine container telemetry events\n\n1. Access the Vaccine Reefer Simulator's Flasgger UI via the following `oc` command:\n\n   ```shell\n   oc get route vaccine-reefer-simulator -o jsonpath=\"http://{.status.ingress[0].host}\"\n   ```\n\n2. Expand the **POST `/control`** and click **Try it out**.\n\n3. In the **Edit Value** text box, update the values of the records accordingly:\n    * **containerID**: `C01`\n    * **nb_of_records**: `500`\n    * **product_id**: `covid-19`\n    * **simulation**: `temperature`\n\n4. Click **Execute**.\n\n### Analyze simulated reefer telemetry data\n\n1. Access the Event Streams Console UI via the following `oc` command:\n\n   ```shell\n   oc get route -n eventstreams ${CLUSTER_NAME}-ibm-es-ui -o jsonpath=\"https://{.status.ingress[0].host}\"\n   ```\n\n2. Click **Topics** from the left navigation menu and select the topic that matches the `KAFKA_MAIN_TOPIC` and `telemetry-topic` values.\n\n3. Explore the messages tab and the individual telemetry records emitted by the Vaccine Reefer Simulator component.\n\n### Analyze generated cold-chain violations\n\n1. Click **Topics** from the left navigation menu and selec the topic that matches the `reefer-topic` value.\n\n2. Explore the messages tab and the observed vaccine cold-chain violation alert events.\n\n3. The reefer container information contained in this topic have been identified as having observed temperatures outside the allowable range more than the allowable number of times, as determined to preserve the state of the vaccine doses contained.\n\n### Perform vaccine container maintenance\n\n<InlineNotification kind=\"warning\"><strong>TODO</strong> - SCORING</InlineNotification>\n","fileAbsolutePath":"/home/runner/work/vaccine-solution-main/vaccine-solution-main/docs/src/pages/use-cases/cold-chain/index.mdx"}}}}